class AsyncClassService:
    # --- A√±adir m√©todo helper para invalidaci√≥n ---
    async def _invalidate_class_caches(self, redis_client: Optional[Redis], gym_id: int, class_id: Optional[int] = None, category_id: Optional[int] = None, difficulty: Optional[str] = None):
        if not redis_client:
            return
        
        keys_to_delete = []
        patterns_to_delete = []
        
        # Clave de detalle
        if class_id:
            keys_to_delete.append(f"schedule:class:detail:{class_id}")
            
        # Patrones de lista general y por gimnasio
        patterns_to_delete.append(f"schedule:classes:gym:{gym_id}:*")
        patterns_to_delete.append(f"schedule:classes:all:*") # Por si acaso, aunque no la estamos usando ahora mismo
        
        # Patrones de b√∫squeda y filtrado
        patterns_to_delete.append(f"schedule:classes:search:gym:{gym_id}:*")
        if category_id:
            patterns_to_delete.append(f"schedule:classes:category:{category_id}:gym:{gym_id}:*")
        if difficulty:
             patterns_to_delete.append(f"schedule:classes:difficulty:{difficulty}:gym:{gym_id}:*")
             
        try:
            if keys_to_delete:
                deleted_keys = await redis_client.delete(*keys_to_delete)
                logger.debug(f"Invalidated {deleted_keys} class detail keys: {keys_to_delete}")
                
            deleted_pattern_count = 0
            for pattern in patterns_to_delete:
                deleted_count = await cache_service.delete_pattern(redis_client, pattern)
                deleted_pattern_count += deleted_count
                logger.debug(f"Invalidated {deleted_count} keys with pattern: {pattern}")
            logger.debug(f"Total invalidated class keys from patterns: {deleted_pattern_count}")
            
        except Exception as e:
            logger.error(f"Error invalidating class cache for gym {gym_id} (class: {class_id}): {e}", exc_info=True)
    # --- Fin m√©todo helper ---
    
    async def get_class(self, db: AsyncSession, class_id: int, gym_id: int, redis_client: Optional[Redis] = None) -> Any:
        """Obtener una clase por ID (con cach√©), asegurando que pertenece al gimnasio"""
        
        cache_key = f"schedule:class:detail:{class_id}"
        
        async def db_fetch():
            class_obj = await async_class_repository.get_async(db, id=class_id)
            if not class_obj:
                    # No lanzar excepci√≥n aqu√≠, dejar que get_or_set devuelva None
                    return None 
            return class_obj
        
        # Intentar obtener de cach√©
        class_cached = await cache_service.get_or_set(
            redis_client=redis_client,
            cache_key=cache_key,
            db_fetch_func=db_fetch,
            model_class=ClassSchema,
            expiry_seconds=3600, # 1 hora
            is_list=False
        )
        
        if not class_cached:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Clase no encontrada"
            )
            
        # Verificar pertenencia al gimnasio despu√©s de obtenerla
        if class_cached.gym_id != gym_id:
             raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="No tienes acceso a esta clase"
            )
            
        return class_cached
    
    async def get_classes(
        self, db: AsyncSession, skip: int = 0, limit: int = 100, active_only: bool = True,
        gym_id: Optional[int] = None, redis_client: Optional[Redis] = None
    ) -> List[Any]:
        """
        Obtener todas las clases, opcionalmente filtradas por gimnasio (con cach√©).
        """
        # Si no hay gym_id, no usar cach√© y ejecutar consulta directa
        if gym_id is None:
            logger.warning("Attempted to get classes without gym_id. Cache disabled and no gym filtering applied.")
            query = db.query(Class).options(joinedload(Class.custom_category))
            if active_only:
                query = query.filter(Class.is_active == True)
            return query.offset(skip).limit(limit).all()
        
        # Si tenemos gym_id, usar cach√©
        cache_key = f"schedule:classes:gym:{gym_id}:active:{active_only}:skip:{skip}:limit:{limit}"
        
        async def db_fetch():
            query = db.query(Class).options(joinedload(Class.custom_category)).filter(Class.gym_id == gym_id)
            if active_only:
                query = query.filter(Class.is_active == True)
            return query.offset(skip).limit(limit).all()
    
        classes = await cache_service.get_or_set(
            redis_client=redis_client,
            cache_key=cache_key,
            db_fetch_func=db_fetch,
            model_class=ClassSchema,
            expiry_seconds=1800, # 30 minutos para listas
            is_list=True
        )
        return classes
    
    async def create_class(self, db: AsyncSession, class_data: ClassCreate, created_by_id: Optional[int] = None, gym_id: int = None, redis_client: Optional[Redis] = None) -> Any:
        """
        Crear una nueva clase e invalidar cach√©.
        """
        # Preparar los datos para la creaci√≥n
        obj_in_data = class_data.model_dump(exclude={"category"})  # Excluir el campo auxiliar category
        
        # Asegurarse de que gym_id est√© presente
        if not gym_id:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Se requiere un ID de gimnasio v√°lido"
            )
            
        # Agregar el gym_id al objeto de datos
        obj_in_data["gym_id"] = gym_id
            
        # Agregar ID del creador si se proporciona
        if created_by_id:
            obj_in_data["created_by"] = created_by_id
        
        # Crear la clase en la BD
        db_obj = await async_class_repository.create_async(db, obj_in=obj_in_data)
        
        # Invalidar cach√© relevante
        await self._invalidate_class_caches(
            redis_client=redis_client, 
            gym_id=gym_id, 
            category_id=db_obj.category_id, 
            difficulty=db_obj.difficulty_level.value if db_obj.difficulty_level else None
        )
        
        return db_obj
    
    async def update_class(self, db: AsyncSession, class_id: int, class_data: ClassUpdate, gym_id: int, redis_client: Optional[Redis] = None) -> Any:
        """Actualizar una clase existente e invalidar cach√©"""
        # Obtener la clase de la BD (no usar cach√© aqu√≠)
        class_obj = await async_class_repository.get_async(db, id=class_id)
        if not class_obj or class_obj.gym_id != gym_id:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Clase no encontrada en este gimnasio"
            )
        
        # Guardar categor√≠a y dificultad originales para invalidaci√≥n
        original_category_id = class_obj.category_id
        original_difficulty = class_obj.difficulty_level.value if class_obj.difficulty_level else None
        
        # Actualizar en BD
        updated_class = async_class_repository.update_async(db, db_obj=class_obj, obj_in=class_data)
        
        # Invalidar cach√©
        await self._invalidate_class_caches(
            redis_client=redis_client, 
            gym_id=gym_id, 
            class_id=class_id, 
            category_id=updated_class.category_id, 
            difficulty=updated_class.difficulty_level.value if updated_class.difficulty_level else None
        )
        # Invalidar tambi√©n para la categor√≠a/dificultad original si cambiaron
        if original_category_id != updated_class.category_id:
             await self._invalidate_class_caches(redis_client=redis_client, gym_id=gym_id, category_id=original_category_id)
        if original_difficulty != (updated_class.difficulty_level.value if updated_class.difficulty_level else None):
             await self._invalidate_class_caches(redis_client=redis_client, gym_id=gym_id, difficulty=original_difficulty)
             
        return updated_class
    
    async def delete_class(self, db: AsyncSession, class_id: int, gym_id: int, redis_client: Optional[Redis] = None) -> Any:
        """Eliminar o inactivar una clase e invalidar cach√©"""
        # Obtener la clase de la BD (no usar cach√©)
        class_obj = await async_class_repository.get_async(db, id=class_id)
        if not class_obj or class_obj.gym_id != gym_id:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Clase no encontrada en este gimnasio"
            )
        
        # Guardar categor√≠a y dificultad para invalidaci√≥n antes de eliminar/inactivar
        category_id = class_obj.category_id
        difficulty = class_obj.difficulty_level.value if class_obj.difficulty_level else None
        
        # Verificar si hay sesiones programadas para esta clase
        sessions = await async_class_session_repository.get_by_class(db, class_id=class_id)
        if sessions:
            # Actualizar el estado de la clase a inactivo en lugar de eliminarla
            result = await async_class_repository.update_async(
                db, db_obj=class_obj, obj_in={"is_active": False}
            )
            action = "inactivated"
        else:
            # Eliminar la clase
            result = await async_class_repository.remove_async(db, id=class_id)
            action = "deleted"
            
        # Invalidar cach√©
        await self._invalidate_class_caches(
            redis_client=redis_client, 
            gym_id=gym_id, 
            class_id=class_id, 
            category_id=category_id, 
            difficulty=difficulty
        )
        
        logger.info(f"Class {class_id} {action} for gym {gym_id}.")
        return result # Devuelve el objeto actualizado o None si se elimin√≥
    
    async def get_classes_by_category(
        self, db: AsyncSession, *, category_id: int, skip: int = 0, limit: int = 100,
        gym_id: Optional[int] = None, redis_client: Optional[Redis] = None
    ) -> List[Any]:
        """
        Obtener clases por ID de categor√≠a, opcionalmente filtradas por gimnasio (con cach√©).
        """
        if gym_id is None:
            logger.warning("Attempted to get classes by category without gym_id. Cache disabled.")
            query = db.query(Class).filter(Class.category_id == category_id, Class.is_active == True)
            return query.offset(skip).limit(limit).all()
            
        cache_key = f"schedule:classes:category:{category_id}:gym:{gym_id}:skip:{skip}:limit:{limit}"
        
        async def db_fetch():
            query = db.query(Class).filter(
                Class.category_id == category_id, 
                Class.gym_id == gym_id, 
                Class.is_active == True
                )
            return query.offset(skip).limit(limit).all()
    
        classes = await cache_service.get_or_set(
            redis_client=redis_client,
            cache_key=cache_key,
            db_fetch_func=db_fetch,
            model_class=ClassSchema,
            expiry_seconds=1800, # 30 mins
            is_list=True
        )
        return classes
    
    async def get_classes_by_difficulty(
        self, db: AsyncSession, *, difficulty: str, skip: int = 0, limit: int = 100,
        gym_id: Optional[int] = None, redis_client: Optional[Redis] = None
    ) -> List[Any]:
        """
        Obtener clases por nivel de dificultad, opcionalmente filtradas por gimnasio (con cach√©).
        """
        if gym_id is None:
            logger.warning("Attempted to get classes by difficulty without gym_id. Cache disabled.")
            
            return query.offset(skip).limit(limit).all()
            
        cache_key = f"schedule:classes:difficulty:{difficulty}:gym:{gym_id}:skip:{skip}:limit:{limit}"
        
        async def db_fetch():
            query = db.query(Class).filter(
                Class.difficulty_level == difficulty, 
                Class.gym_id == gym_id, 
                Class.is_active == True
            )
            return query.offset(skip).limit(limit).all()
    
        classes = await cache_service.get_or_set(
            redis_client=redis_client,
            cache_key=cache_key,
            db_fetch_func=db_fetch,
            model_class=ClassSchema,
            expiry_seconds=1800, # 30 mins
            is_list=True
        )
        return classes
    
    async def search_classes(
        self, db: AsyncSession, *, search: str, skip: int = 0, limit: int = 100,
        gym_id: Optional[int] = None, redis_client: Optional[Redis] = None
    ) -> List[Any]:
        """
        Buscar clases por nombre o descripci√≥n, opcionalmente filtradas por gimnasio (con cach√©).
        """
        if gym_id is None:
            logger.warning("Attempted to search classes without gym_id. Cache disabled.")
            search_pattern = f"%{search}%"
            query = db.query(Class).filter(
                or_(
                    Class.name.ilike(search_pattern),
                    Class.description.ilike(search_pattern)
                ),
                Class.is_active == True
            )
            return query.offset(skip).limit(limit).all()
            
        # Codificar t√©rmino de b√∫squeda para la clave de cach√©
        safe_search = ''.join(c if c.isalnum() else '_' for c in search)
        cache_key = f"schedule:classes:search:gym:{gym_id}:term:{safe_search}:skip:{skip}:limit:{limit}"
        
        async def db_fetch():
            search_pattern = f"%{search}%"
            query = db.query(Class).filter(
                    or_(
                        Class.name.ilike(search_pattern),
                        Class.description.ilike(search_pattern)
                    ),
                    Class.gym_id == gym_id,
                    Class.is_active == True
                )
            return query.offset(skip).limit(limit).all()
        
        classes = await cache_service.get_or_set(
            redis_client=redis_client,
            cache_key=cache_key,
            db_fetch_func=db_fetch,
            model_class=ClassSchema,
            expiry_seconds=600, # 10 mins para b√∫squedas
            is_list=True
        )
        return classes


class AsyncClassSessionService:
    async def get_session(self, db: AsyncSession, session_id: int, gym_id: int, redis_client: Optional[Redis] = None) -> Any:
        """Obtener una sesi√≥n por ID con cach√©"""
        # Verificar que la sesi√≥n pertenece al gimnasio
        session = await async_class_session_repository.get_async(db, id=session_id)
        if not session or session.gym_id != gym_id:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Sesi√≥n no encontrada en este gimnasio"
            )
        
        # Si no hay redis_client, devolver directamente
        if not redis_client:
            return session
        
        cache_key = f"schedule:session:detail:{session_id}"
        
        async def db_fetch():
            return await async_class_session_repository.get_async(db, id=session_id)
        
        # Usar el servicio de cach√© gen√©rico
        from app.services.cache_service import cache_service
        from app.schemas.schedule import ClassSession
        
        cached_session = await cache_service.get_or_set(
            redis_client=redis_client,
            cache_key=cache_key,
            db_fetch_func=db_fetch,
            model_class=ClassSession,
            expiry_seconds=1800,  # 30 minutos para sesiones individuales
            is_list=False
        )
        
        return cached_session
    
    async def get_session_with_details(self, db: AsyncSession, session_id: int, gym_id: int, redis_client: Optional[Redis] = None) -> Dict[str, Any]:
        """Obtener una sesi√≥n con detalles completos (clase, trainer, participantes) con cach√©"""
        # Verificar que la sesi√≥n pertenece al gimnasio
        session = await async_class_session_repository.get_async(db, id=session_id)
        if not session or session.gym_id != gym_id:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Sesi√≥n no encontrada en este gimnasio"
            )
        
        # Si no hay redis_client, usar versi√≥n sin cach√©
        if not redis_client:
            raw = await async_class_session_repository.get_with_availability(db, session_id=session_id)
            if raw and "session" in raw:
                session_with_tz = await populate_sessions_with_timezone([raw["session"]], gym_id, db)
                if session_with_tz:
                    raw["session"] = session_with_tz[0]
            return raw
        
        cache_key = f"schedule:session:detail_with_availability:{session_id}"
        
        async def db_fetch():
            raw = await async_class_session_repository.get_with_availability(db, session_id=session_id)

            if not raw:
                return None

            # Convertir los modelos ORM a esquemas serializables
            from app.schemas.schedule import ClassSession, Class

            try:
                # Poblar campos timezone para la sesi√≥n
                session_with_tz = await populate_sessions_with_timezone([raw["session"]], gym_id, db)
                if session_with_tz:
                    raw["session"] = session_with_tz[0]
                else:
                    raw["session"] = ClassSession.model_validate(raw["session"]).model_dump()
                
                raw["class"] = Class.model_validate(raw["class"]).model_dump()
            except Exception as e:
                logger.error(f"Error al convertir modelos a dict para cach√©: {e}")

            return raw
        
        # Usar el servicio de cach√© gen√©rico
        from app.services.cache_service import cache_service
        
        # Para este caso, no podemos usar un schema espec√≠fico porque devuelve un dict complejo
        # Usamos serializaci√≥n JSON directa
        session_details = await cache_service.get_or_set_json(
            redis_client=redis_client,
            cache_key=cache_key,
            db_fetch_func=db_fetch,
            expiry_seconds=900,  # 15 minutos para detalles con disponibilidad
        )
        
        return session_details
    
    async def create_session(
        self, db: AsyncSession, session_data: ClassSessionCreate, gym_id: int, created_by_id: Optional[int] = None, redis_client: Optional[Redis] = None
    ) -> Any:
        """Crear una nueva sesi√≥n de clase e invalidar cach√©"""
        # Nota: A√±adir gym_id y redis_client
        
        # Verificar que la clase exista, est√© activa y pertenezca al gimnasio
        class_obj = await async_class_repository.get_async(db, id=session_data.class_id)
        if not class_obj:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Clase no encontrada"
            )
        if not class_obj.is_active:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="No se pueden crear sesiones para una clase inactiva"
            )
        if class_obj.gym_id != gym_id:
             raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="La clase especificada no pertenece a este gimnasio"
            )
        
        # Obtener el gimnasio para su timezone
        from app.repositories.gym import gym_repository
        gym = gym_repository.get_async(db, id=gym_id)
        if not gym:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Gimnasio no encontrado"
            )
        
        # Calcular hora de fin si no se proporciona
        obj_in_data = session_data.model_dump()
        if not obj_in_data.get_async("end_time") and class_obj.duration:
            start_time = obj_in_data.get_async("start_time")
            if start_time:
                end_time = start_time + timedelta(minutes=class_obj.duration)
                obj_in_data["end_time"] = end_time
        
        # Convertir tiempos de hora local del gimnasio a UTC
        start_time_local = obj_in_data.get_async("start_time")
        end_time_local = obj_in_data.get_async("end_time")
        
        logger.info(f"üîÑ TIMEZONE CONVERSION in create_session:")
        logger.info(f"   Gym timezone: {gym.timezone}")
        logger.info(f"   start_time_local (antes): {start_time_local}")
        logger.info(f"   end_time_local (antes): {end_time_local}")
        logger.info(f"   start_time_local type: {type(start_time_local)}")
        logger.info(f"   start_time_local tzinfo: {getattr(start_time_local, 'tzinfo', 'No tzinfo')}")
        
        if start_time_local and end_time_local:
            # Normalizar a UTC: soporta input naive (hora local gym) o aware
            from app.core.timezone_utils import normalize_to_utc
            start_time_utc = normalize_to_utc(start_time_local, gym.timezone)
            end_time_utc = normalize_to_utc(end_time_local, gym.timezone)
            
            logger.info(f"   start_time_utc (despu√©s): {start_time_utc}")
            logger.info(f"   end_time_utc (despu√©s): {end_time_utc}")
            logger.info(f"   start_time_utc type: {type(start_time_utc)}")
            logger.info(f"   start_time_utc tzinfo: {getattr(start_time_utc, 'tzinfo', 'No tzinfo')}")
            
            obj_in_data["start_time"] = start_time_utc
            obj_in_data["end_time"] = end_time_utc
        else:
            logger.warning(f"   ‚ö†Ô∏è start_time o end_time faltantes, no se puede convertir timezone")
        
        # Agregar ID del creador si se proporciona
        if created_by_id:
            obj_in_data["created_by"] = created_by_id
        
        # Asegurar que gym_id est√© presente y sea el correcto
        obj_in_data["gym_id"] = gym_id
        
        # Crear la sesi√≥n
        created_session = await async_class_session_repository.create_async(
            db, obj_in=ClassSessionCreate(**obj_in_data)
        )
        
        logger.info(f"‚úÖ SESSION CREATED in database:")
        logger.info(f"   Session ID: {created_session.id}")
        logger.info(f"   start_time stored: {created_session.start_time}")
        logger.info(f"   end_time stored: {created_session.end_time}")
        logger.info(f"   start_time type: {type(created_session.start_time)}")
        logger.info(f"   start_time tzinfo: {getattr(created_session.start_time, 'tzinfo', 'No tzinfo')}")
    
        # Invalidar cach√©s relevantes (ej. listas de sesiones futuras, por fecha, por trainer, etc.)
        await self._invalidate_session_caches(redis_client, gym_id=gym_id, trainer_id=created_session.trainer_id, class_id=created_session.class_id)
        
        return created_session
    
    # A√±adir m√©todo helper para invalidar cach√© de sesi√≥n
    async def _invalidate_session_caches(self, redis_client: Optional[Redis], gym_id: int, session_id: Optional[int] = None, trainer_id: Optional[int] = None, class_id: Optional[int] = None):
        """
        Invalidar cach√©s de sesiones de manera inteligente usando tracking sets.
        """
        if not redis_client:
            return
            
        from app.services.cache_service import cache_service
        
        keys_to_delete = []
        tracking_sets_to_process = []

        # Cach√©s espec√≠ficos de sesi√≥n
        if session_id:
            keys_to_delete.extend([
                f"schedule:session:detail:{session_id}",
                f"schedule:session:detail_with_availability:{session_id}",
                f"schedule:participations:session:{session_id}:gym:{gym_id}:*"
            ])
        
        # Tracking sets a procesar para invalidaci√≥n masiva
        tracking_sets_to_process.append(f"cache_keys:sessions:{gym_id}")
        
        if trainer_id:
            tracking_sets_to_process.append(f"cache_keys:sessions:trainer:{trainer_id}")
            
        if class_id:
            tracking_sets_to_process.append(f"cache_keys:sessions:class:{class_id}")
        
        try:
            # Eliminar claves espec√≠ficas
            if keys_to_delete:
                # Separar claves directas de patrones
                direct_keys = [k for k in keys_to_delete if '*' not in k]
                pattern_keys = [k for k in keys_to_delete if '*' in k]
                
                if direct_keys:
                    deleted_keys = await redis_client.delete(*direct_keys)
                    logger.debug(f"Invalidated {deleted_keys} direct session keys: {direct_keys}")
                
                # Procesar patrones
                for pattern in pattern_keys:
                    deleted_count = await cache_service.delete_pattern(redis_client, pattern)
                    logger.debug(f"Invalidated {deleted_count} keys with pattern: {pattern}")
            
            # Procesar tracking sets para invalidaci√≥n inteligente
            total_invalidated = 0
            for tracking_set in tracking_sets_to_process:
                try:
                    # Obtener todas las claves del tracking set
                    cached_keys = await redis_client.smembers(tracking_set)
                    if cached_keys:
                        # Convertir bytes a strings si es necesario
                        if isinstance(next(iter(cached_keys)), bytes):
                            cached_keys = [key.decode('utf-8') for key in cached_keys]
                        
                        # Eliminar las claves
                        deleted_count = await redis_client.delete(*cached_keys)
                        total_invalidated += deleted_count
                        
                        # Limpiar el tracking set
                        await redis_client.delete(tracking_set)
                        
                        logger.debug(f"Invalidated {deleted_count} cached keys from tracking set {tracking_set}")
                    
                except Exception as set_error:
                    logger.warning(f"Error processing tracking set {tracking_set}: {set_error}")
            
            if total_invalidated > 0:
                logger.info(f"Total invalidated session cache keys: {total_invalidated}")
            
        except Exception as e:
            logger.error(f"Error invalidating session caches for gym {gym_id}: {e}", exc_info=True)

    async def create_recurring_sessions(
        self, db: AsyncSession, 
        base_session_data: ClassSessionCreate, 
        start_date: date,
        end_date: date,
        days_of_week: List[int],  # 0=Lunes, 1=Martes, etc.
        created_by_id: Optional[int] = None,
        gym_id: int = None, # A√±adir gym_id
        redis_client: Optional[Redis] = None # A√±adir redis_client
    ) -> List[Any]:
        """Crear sesiones recurrentes basadas en d√≠as de la semana e invalidar cach√©"""
        if not gym_id:
             raise HTTPException(status_code=400, detail="Gym ID is required")

        # Verificar que la clase exista, est√© activa y pertenezca al gimnasio
        class_obj = await async_class_repository.get_async(db, id=base_session_data.class_id)
        if not class_obj or class_obj.gym_id != gym_id or not class_obj.is_active:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Clase inv√°lida, inactiva o no pertenece a este gimnasio"
            )
        
        # Obtener el gimnasio para su timezone
        from app.repositories.gym import gym_repository
        gym = gym_repository.get_async(db, id=gym_id)
        if not gym:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Gimnasio no encontrado"
            )
        
        # Preparar datos base para las sesiones
        session_base_data = base_session_data.model_dump()
        session_base_data["gym_id"] = gym_id # Asegurar gym_id
        if created_by_id:
            session_base_data["created_by"] = created_by_id
            
        # Marcar que son sesiones recurrentes
        session_base_data["is_recurring"] = True
        session_base_data["recurrence_pattern"] = f"WEEKLY:{','.join(map(str, days_of_week))}"
        
        # Obtener la hora de inicio y fin de la sesi√≥n base
        base_start_time = session_base_data["start_time"]
        base_end_time = session_base_data["end_time"]
        
        # Necesitamos solo la hora/minutos, no la fecha
        base_start_hour = base_start_time.hour
        base_start_minute = base_start_time.minute
        
        # Si end_time est√° definido, extraer tambi√©n su hora/minutos
        if base_end_time:
            base_end_hour = base_end_time.hour
            base_end_minute = base_end_time.minute
            # Calcular duraci√≥n si no est√° disponible
            duration_minutes = ((base_end_hour * 60 + base_end_minute) - 
                              (base_start_hour * 60 + base_start_minute))
        else:
            # Si no hay end_time pero tenemos la duraci√≥n de la clase
            duration_minutes = class_obj.duration
        
        created_sessions = []
        current_date = start_date
        
        # Iterar por cada d√≠a en el rango
        while current_date <= end_date:
            # Verificar si el d√≠a actual est√° en la lista de d√≠as seleccionados
            if current_date.weekday() in days_of_week:
                # Crear una copia de los datos base para esta sesi√≥n
                session_data = session_base_data.copy()
                
                # Crear datetime para este d√≠a espec√≠fico con la hora base
                new_start_datetime = datetime.combine(
                    current_date, 
                    time(hour=base_start_hour, minute=base_start_minute)
                )
                
                session_data["start_time"] = new_start_datetime
                
                # Calcular end_time basado en la duraci√≥n
                if "end_time" in session_data and session_data["end_time"]:
                    # Si tenemos end_time, crear uno nuevo con la misma fecha
                    new_end_datetime = datetime.combine(
                        current_date,
                        time(hour=base_end_hour, minute=base_end_minute)
                    )
                    session_data["end_time"] = new_end_datetime
                elif duration_minutes:
                    # Calcular end_time basado en la duraci√≥n
                    new_end_datetime = new_start_datetime + timedelta(minutes=duration_minutes)
                    session_data["end_time"] = new_end_datetime
                
                # Convertir/normalizar tiempos a UTC antes de crear la sesi√≥n
                from app.core.timezone_utils import normalize_to_utc
                session_data["start_time"] = normalize_to_utc(session_data["start_time"], gym.timezone)
                session_data["end_time"] = normalize_to_utc(session_data["end_time"], gym.timezone)
                
                # Crear la sesi√≥n
                session = await async_class_session_repository.create_async(
                    db, obj_in=session_data
                )
                created_sessions.append(session)
                
            # Avanzar al siguiente d√≠a
            current_date += timedelta(days=1)
            
        # Invalidar cach√©s relevantes una vez despu√©s del bucle
        if created_sessions:
             await self._invalidate_session_caches(redis_client, gym_id=gym_id, trainer_id=base_session_data.trainer_id, class_id=base_session_data.class_id)
        
        return created_sessions
    
    async def update_session(
        self, db: AsyncSession, session_id: int, session_data: ClassSessionUpdate, gym_id: int, redis_client: Optional[Redis] = None
    ) -> Any:
        """Actualizar una sesi√≥n existente e invalidar cach√©"""
        # Nota: A√±adir gym_id y redis_client
        session = await async_class_session_repository.get_async(db, id=session_id)
        if not session or session.gym_id != gym_id:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Sesi√≥n no encontrada en este gimnasio"
            )
        
        # Obtener el gimnasio para su timezone
        from app.repositories.gym import gym_repository
        gym = gym_repository.get_async(db, id=gym_id)
        if not gym:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Gimnasio no encontrado"
            )
        
        # Guardar datos originales para invalidaci√≥n si cambian
        original_trainer_id = session.trainer_id
        original_class_id = session.class_id
        
        # Preparar datos de actualizaci√≥n
        update_data = session_data.model_dump(exclude_unset=True)
        
        # Si se est√°n actualizando los tiempos, normalizar a UTC
        if "start_time" in update_data or "end_time" in update_data:
            from app.core.timezone_utils import normalize_to_utc
            if "start_time" in update_data and update_data["start_time"] is not None:
                update_data["start_time"] = normalize_to_utc(update_data["start_time"], gym.timezone)
            if "end_time" in update_data and update_data["end_time"] is not None:
                update_data["end_time"] = normalize_to_utc(update_data["end_time"], gym.timezone)
        
        # Actualizar en BD
        updated_session = await async_class_session_repository.update_async(
            db, db_obj=session, obj_in=update_data
        )
        
        # Invalidar cach√©
        await self._invalidate_session_caches(
            redis_client, 
            gym_id=gym_id, 
            session_id=session_id, 
            trainer_id=updated_session.trainer_id, 
            class_id=updated_session.class_id
        )
        # Invalidar tambi√©n para trainer/clase original si cambiaron
        if original_trainer_id != updated_session.trainer_id:
             await self._invalidate_session_caches(redis_client, gym_id=gym_id, trainer_id=original_trainer_id)
        if original_class_id != updated_session.class_id:
             await self._invalidate_session_caches(redis_client, gym_id=gym_id, class_id=original_class_id)
             
        return updated_session
    
    async def cancel_session(self, db: AsyncSession, session_id: int, gym_id: int, redis_client: Optional[Redis] = None) -> Any:
        """Cancelar una sesi√≥n e invalidar cach√©"""
        # Nota: A√±adir gym_id y redis_client
        session = await async_class_session_repository.get_async(db, id=session_id)
        if not session or session.gym_id != gym_id:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Sesi√≥n no encontrada en este gimnasio"
            )
        
        # Guardar datos para invalidaci√≥n
        trainer_id = session.trainer_id
        class_id = session.class_id
        
        # Actualizar el estado de la sesi√≥n a cancelado
        cancelled_session = await async_class_session_repository.update_async(
            db, db_obj=session, 
            obj_in={"status": ClassSessionStatus.CANCELLED}
        )
    
        # Invalidar cach√©
        await self._invalidate_session_caches(
            redis_client, 
            gym_id=gym_id, 
            session_id=session_id, 
            trainer_id=trainer_id, 
            class_id=class_id
        )
        
        return cancelled_session
    
    async def get_upcoming_sessions(
        self, db: AsyncSession, skip: int = 0, limit: int = 100, gym_id: Optional[int] = None, redis_client: Optional[Redis] = None
    ) -> List[Any]:
        """
        Obtener las pr√≥ximas sesiones programadas, opcionalmente filtradas por gimnasio (con cach√©).
        """
        # Si no hay gym_id, usar versi√≥n sin cach√©
        if gym_id is None:
            logger.warning("Attempted to get upcoming sessions without gym_id. Cache disabled.")
            return await async_class_session_repository.get_upcoming_sessions(db, skip=skip, limit=limit)
        
        # Si no hay redis_client, usar versi√≥n sin cach√©
        if not redis_client:
            return async_class_session_repository.get_upcoming_sessions(
                db, skip=skip, limit=limit, gym_id=gym_id
            )
            
        cache_key = f"schedule:sessions:upcoming:gym:{gym_id}:skip:{skip}:limit:{limit}"
        tracking_set_key = f"cache_keys:sessions:{gym_id}"
        
        # Indica si el resultado vino de la BD
        fetched_from_db = False
        
        async def db_fetch():
            nonlocal fetched_from_db
            result = await async_class_session_repository.get_upcoming_sessions(
                db, skip=skip, limit=limit, gym_id=gym_id
            )
            fetched_from_db = True
            return result
        
        # Usar el servicio de cach√© gen√©rico
        from app.services.cache_service import cache_service
        from app.schemas.schedule import ClassSession
        
        sessions = await cache_service.get_or_set(
            redis_client=redis_client,
            cache_key=cache_key,
            db_fetch_func=db_fetch,
            model_class=ClassSession,
            expiry_seconds=300,  # 5 minutos para sesiones pr√≥ximas
            is_list=True
        )
        
        # A√±adir a tracking set para invalidaci√≥n
        if fetched_from_db:
            try:
                await redis_client.sadd(tracking_set_key, cache_key)
                await redis_client.expire(tracking_set_key, 3600)  # 1 hora de tracking
            except Exception as e:
                logger.warning(f"No se pudo a√±adir clave a tracking set: {e}")
        
        return sessions
    
    async def get_sessions_by_date_range(
        self, db: AsyncSession, start_date: date, end_date: date, 
        skip: int = 0, limit: int = 100, gym_id: Optional[int] = None, redis_client: Optional[Redis] = None
    ) -> List[Any]:
        """
        Obtener sesiones en un rango de fechas, opcionalmente filtradas por gimnasio (con cach√©).
        """
        # Si no hay gym_id, usar versi√≥n sin cach√©
        if gym_id is None:
            logger.warning("Attempted to get sessions by date range without gym_id. Cache disabled.")
            start_datetime = datetime.combine(start_date, time.min)
            end_datetime = datetime.combine(end_date, time.max)
            return await async_class_session_repository.get_by_date_range(db, start_date=start_datetime, end_date=end_datetime, skip=skip, limit=limit)

        # Si no hay redis_client, usar versi√≥n sin cach√©
        if not redis_client:
            start_datetime = datetime.combine(start_date, time.min)
            end_datetime = datetime.combine(end_date, time.max)
            return async_class_session_repository.get_by_date_range(
                db, start_date=start_datetime, end_date=end_datetime,
                skip=skip, limit=limit, gym_id=gym_id
            )

        # Formatear fechas para la clave
        start_str = start_date.isoformat()
        end_str = end_date.isoformat()
        cache_key = f"schedule:sessions:range:gym:{gym_id}:start:{start_str}:end:{end_str}:skip:{skip}:limit:{limit}"
        tracking_set_key = f"cache_keys:sessions:{gym_id}"
        
        # Indica si el resultado vino de la BD
        fetched_from_db = False
        
        async def db_fetch():
            nonlocal fetched_from_db
            start_datetime = datetime.combine(start_date, time.min)
            end_datetime = datetime.combine(end_date, time.max)
            result = await async_class_session_repository.get_by_date_range(
                db, start_date=start_datetime, end_date=end_datetime,
                skip=skip, limit=limit, gym_id=gym_id
            )
            fetched_from_db = True
            return result
        
        # Usar el servicio de cach√© gen√©rico
        from app.services.cache_service import cache_service
        from app.schemas.schedule import ClassSession
        
        sessions = await cache_service.get_or_set(
            redis_client=redis_client,
            cache_key=cache_key,
            db_fetch_func=db_fetch,
            model_class=ClassSession,
            expiry_seconds=900,  # 15 minutos para rangos de fechas
            is_list=True
        )
        
        # A√±adir a tracking set para invalidaci√≥n
        if fetched_from_db:
            try:
                await redis_client.sadd(tracking_set_key, cache_key)
                await redis_client.expire(tracking_set_key, 3600)  # 1 hora de tracking
            except Exception as e:
                logger.warning(f"No se pudo a√±adir clave a tracking set: {e}")
        
        return sessions
    
    async def get_sessions_by_trainer(
        self, db: AsyncSession, trainer_id: int, skip: int = 0, limit: int = 100,
        upcoming_only: bool = False, gym_id: Optional[int] = None, redis_client: Optional[Redis] = None
    ) -> List[Any]:
        """
        Obtener sesiones de un entrenador espec√≠fico, opcionalmente filtradas por gimnasio (con cach√©).
        """
        # Si no hay gym_id, usar versi√≥n sin cach√©
        if gym_id is None:
            logger.warning("Attempted to get sessions by trainer without gym_id. Cache disabled.")
            if upcoming_only:
                return await async_class_session_repository.get_trainer_upcoming_sessions(db, trainer_id=trainer_id, skip=skip, limit=limit)
            return await async_class_session_repository.get_by_trainer(db, trainer_id=trainer_id, skip=skip, limit=limit)
        
        # Si no hay redis_client, usar versi√≥n sin cach√©
        if not redis_client:
            if upcoming_only:
                return async_class_session_repository.get_trainer_upcoming_sessions(
                    db, trainer_id=trainer_id, skip=skip, limit=limit, gym_id=gym_id
                )
            return async_class_session_repository.get_by_trainer(
                db, trainer_id=trainer_id, skip=skip, limit=limit, gym_id=gym_id
            )
            
        cache_key = f"schedule:sessions:trainer:{trainer_id}:gym:{gym_id}:upcoming:{upcoming_only}:skip:{skip}:limit:{limit}"
        tracking_set_key = f"cache_keys:sessions:{gym_id}"
        trainer_tracking_key = f"cache_keys:sessions:trainer:{trainer_id}"
        
        # Indica si el resultado vino de la BD
        fetched_from_db = False
        
        async def db_fetch():
            nonlocal fetched_from_db
            if upcoming_only:
                result = await async_class_session_repository.get_trainer_upcoming_sessions(
                    db, trainer_id=trainer_id, skip=skip, limit=limit, gym_id=gym_id
                )
            else:
                result = await async_class_session_repository.get_by_trainer(
                    db, trainer_id=trainer_id, skip=skip, limit=limit, gym_id=gym_id
                )
            fetched_from_db = True
            return result
        
        # Usar el servicio de cach√© gen√©rico
        from app.services.cache_service import cache_service
        from app.schemas.schedule import ClassSession
        
        sessions = await cache_service.get_or_set(
            redis_client=redis_client,
            cache_key=cache_key,
            db_fetch_func=db_fetch,
            model_class=ClassSession,
            expiry_seconds=600,  # 10 minutos para sesiones por trainer
            is_list=True
        )
        
        # A√±adir a tracking sets para invalidaci√≥n
        if fetched_from_db:
            try:
                await redis_client.sadd(tracking_set_key, cache_key)
                await redis_client.sadd(trainer_tracking_key, cache_key)
                await redis_client.expire(tracking_set_key, 3600)  # 1 hora de tracking
                await redis_client.expire(trainer_tracking_key, 3600)  # 1 hora de tracking
            except Exception as e:
                logger.warning(f"No se pudo a√±adir clave a tracking sets: {e}")
        
        return sessions
    
    async def get_sessions_by_class(
        self, db: AsyncSession, class_id: int, skip: int = 0, limit: int = 100, gym_id: Optional[int] = None, redis_client: Optional[Redis] = None
    ) -> List[Any]:
        """
        Obtener sesiones de una clase espec√≠fica, opcionalmente filtradas por gimnasio (con cach√©).
        """
        # Si no hay gym_id, usar versi√≥n sin cach√©
        if gym_id is None:
            logger.warning("Attempted to get sessions by class without gym_id. Cache disabled.")
            return await async_class_session_repository.get_by_class(db, class_id=class_id, skip=skip, limit=limit)

        # Si no hay redis_client, usar versi√≥n sin cach√©
        if not redis_client:
            return async_class_session_repository.get_by_class(
                db, class_id=class_id, skip=skip, limit=limit, gym_id=gym_id
            )

        cache_key = f"schedule:sessions:class:{class_id}:gym:{gym_id}:skip:{skip}:limit:{limit}"
        tracking_set_key = f"cache_keys:sessions:{gym_id}"
        class_tracking_key = f"cache_keys:sessions:class:{class_id}"
        
        # Indica si el resultado vino de la BD
        fetched_from_db = False
        
        async def db_fetch():
            nonlocal fetched_from_db
            result = await async_class_session_repository.get_by_class(
                db, class_id=class_id, skip=skip, limit=limit, gym_id=gym_id
            )
            fetched_from_db = True
            return result
        
        # Usar el servicio de cach√© gen√©rico
        from app.services.cache_service import cache_service
        from app.schemas.schedule import ClassSession
        
        sessions = await cache_service.get_or_set(
            redis_client=redis_client,
            cache_key=cache_key,
            db_fetch_func=db_fetch,
            model_class=ClassSession,
            expiry_seconds=600,  # 10 minutos para sesiones por clase
            is_list=True
        )
        
        # A√±adir a tracking sets para invalidaci√≥n
        if fetched_from_db:
            try:
                await redis_client.sadd(tracking_set_key, cache_key)
                await redis_client.sadd(class_tracking_key, cache_key)
                await redis_client.expire(tracking_set_key, 3600)  # 1 hora de tracking
                await redis_client.expire(class_tracking_key, 3600)  # 1 hora de tracking
            except Exception as e:
                logger.warning(f"No se pudo a√±adir clave a tracking sets: {e}")
        
        return sessions


class AsyncClassParticipationService:
    async def register_for_class(self, db: AsyncSession, member_id: int, session_id: int, gym_id: int, redis_client: Optional[Redis] = None) -> Any:
        """Registrar a un miembro en una sesi√≥n de clase e invalidar cach√© de sesi√≥n"""
        # Nota: A√±adir gym_id y redis_client
        # Verificar si la sesi√≥n existe, est√° programada y pertenece al gimnasio
        session_data = await async_class_session_repository.get_with_availability(db, session_id=session_id)
        if not session_data or session_data["session"].gym_id != gym_id:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Sesi√≥n no encontrada en este gimnasio"
            )
        
        session = session_data["session"]
        class_obj = session_data["class"] # Ya sabemos que la sesi√≥n pertenece al gym_id
        
        # Validar que la sesi√≥n est√© en estado programado
        if session.status != ClassSessionStatus.SCHEDULED:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="No se puede registrar en una sesi√≥n que no est√° programada"
            )
        
        # Obtener informaci√≥n del gimnasio para usar su timezone
        from app.repositories.gym import gym_repository
        gym = gym_repository.get_async(db, id=gym_id)
        if not gym:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Gimnasio no encontrado"
            )
        
        # Validar que la sesi√≥n no haya comenzado a√∫n usando timezone del gimnasio
        if not is_session_in_future(session.start_time, gym.timezone):
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="No se puede registrar en una sesi√≥n que ya ha comenzado o terminado"
            )
        
        # Validar que la sesi√≥n no est√© llena
        if session_data["is_full"]:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="La sesi√≥n est√° llena"
            )
        
        # Verificar si el miembro ya est√° registrado
        existing = await async_class_participation_repository.get_by_session_and_member(
            db, session_id=session_id, member_id=member_id, gym_id=gym_id # A√±adir gym_id
        )
        
        participation_result = None
        if existing:
            if existing.status == ClassParticipationStatus.CANCELLED:
                # Reactivar registro
                participation_result = await async_class_participation_repository.update_async(
                    db, db_obj=existing,
                    obj_in={
                        "status": ClassParticipationStatus.REGISTERED,
                        "cancellation_time": None,
                        "cancellation_reason": None
                    }
                )
            else:
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail="Ya est√°s registrado en esta clase"
                )
        else:
            # Crear nueva participaci√≥n con manejo de carrera por constraint √∫nico
            participation_data = {
                "session_id": session_id,
                "member_id": member_id,
                "status": ClassParticipationStatus.REGISTERED,
                "gym_id": gym_id  # Asignar el gym_id
            }
            from sqlalchemy.exc import IntegrityError
            try:
                participation_result = await async_class_participation_repository.create_async(
                    db, obj_in=participation_data
                )
            except IntegrityError:
                # Otro proceso registr√≥ simult√°neamente; recuperar el existente
                await db.rollback()
                participation_result = await async_class_participation_repository.get_by_session_and_member(
                    db, session_id=session_id, member_id=member_id, gym_id=gym_id
                )
        
        # Actualizar contador de participantes y validar resultado
        if participation_result:
            async_class_session_repository.update_participant_count(db, session_id=session_id)
            # Invalidar cach√©s de sesi√≥n y participaci√≥n al final
            await self._invalidate_session_caches_from_participation(
                session_id=session_id,
                gym_id=gym_id,
                redis_client=redis_client,
                trainer_id=session.trainer_id, 
                class_id=session.class_id
            )
            # Invalidar cache de participation status del miembro
            await self.invalidate_member_participation_cache(
                member_id=member_id, gym_id=gym_id, redis_client=redis_client
            )
            return participation_result
        else:
             # Si por alguna raz√≥n no se cre√≥/actualiz√≥ la participaci√≥n
             raise HTTPException(status_code=500, detail="No se pudo completar el registro")

    async def cancel_registration(self, db: AsyncSession, member_id: int, session_id: int, gym_id: int, reason: Optional[str] = None, redis_client: Optional[Redis] = None) -> Any:
        """Cancelar el registro de un miembro en una sesi√≥n e invalidar cach√© de sesi√≥n"""
        # Nota: A√±adir gym_id y redis_client
        # Verificar si la participaci√≥n existe y pertenece al gimnasio
        participation = await async_class_participation_repository.get_by_session_and_member(
            db, session_id=session_id, member_id=member_id, gym_id=gym_id # A√±adir gym_id
        )
        
        if not participation:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="No est√°s registrado en esta clase"
            )
        
        # ... (resto de validaciones: status) ...
        session = await async_class_session_repository.get_async(db, id=session_id) # Necesitamos la sesi√≥n para invalidar
        
        # Cancelar la participaci√≥n
        cancelled_participation = await async_class_participation_repository.cancel_participation(
            db, session_id=session_id, member_id=member_id, reason=reason, gym_id=gym_id # Pasar gym_id
        )
        
        # Actualizar contador y validar resultado
        if cancelled_participation:
            # Actualizar contador (cancel_participation ya lo hace, pero aseguramos)
            async_class_session_repository.update_participant_count(db, session_id=session_id)
            # Invalidar cach√©s de sesi√≥n
            if session: # Asegurar que tenemos la sesi√≥n
                await self._invalidate_session_caches_from_participation(
                    session_id=session_id,
                    gym_id=gym_id,
                    redis_client=redis_client,
                    trainer_id=session.trainer_id, 
                    class_id=session.class_id
                )
            # Invalidar cache de participation status del miembro
            await self.invalidate_member_participation_cache(
                member_id=member_id, gym_id=gym_id, redis_client=redis_client
            )
            return cancelled_participation
        else:
             raise HTTPException(status_code=500, detail="No se pudo completar la cancelaci√≥n")
    
    async def mark_attendance(self, db: AsyncSession, member_id: int, session_id: int, gym_id: int, redis_client: Optional[Redis] = None) -> Any:
        """Marcar la asistencia de un miembro a una sesi√≥n"""
        # Nota: A√±adir gym_id. La invalidaci√≥n no es estrictamente necesaria aqu√≠
        #       a menos que afecte a listas futuras o algo similar.
        # Verificar si la participaci√≥n existe y pertenece al gimnasio
        participation = await async_class_participation_repository.get_by_session_and_member(
            db, session_id=session_id, member_id=member_id, gym_id=gym_id
        )
        
        if not participation:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="El miembro no est√° registrado en esta clase"
            )
        
        # ... (resto de validaciones: status) ...
        
        # Marcar la asistencia
        return async_class_participation_repository.mark_attendance(
            db, session_id=session_id, member_id=member_id, gym_id=gym_id # Pasar gym_id
        )
    
    async def mark_no_show(self, db: AsyncSession, member_id: int, session_id: int, gym_id: int, redis_client: Optional[Redis] = None) -> Any:
        """Marcar que un miembro no asisti√≥ a una sesi√≥n"""
        # Nota: A√±adir gym_id. Similar a mark_attendance, la invalidaci√≥n
        #       no suele ser cr√≠tica aqu√≠.
        # Verificar si la participaci√≥n existe y pertenece al gimnasio
        participation = await async_class_participation_repository.get_by_session_and_member(
            db, session_id=session_id, member_id=member_id, gym_id=gym_id
        )
        
        if not participation:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="El miembro no est√° registrado en esta clase"
            )
        
        # ... (resto de validaciones: status) ...
        
        # Marcar como no-show
        updated = await async_class_participation_repository.update_async(
            db, db_obj=participation,
            obj_in={"status": ClassParticipationStatus.NO_SHOW}
        )
        
        return updated
    
    async def get_session_participants(
        self, db: AsyncSession, session_id: int, skip: int = 0, limit: int = 100, gym_id: Optional[int] = None, redis_client: Optional[Redis] = None
    ) -> List[Any]:
        """Obtener todos los participantes de una sesi√≥n (con cach√©)"""
        # Nota: A√±adir redis_client
        if gym_id is None:
             logger.warning("Attempted to get session participants without gym_id. Cache disabled.")
             return await async_class_participation_repository.get_by_session(db, session_id=session_id, skip=skip, limit=limit)
             
        cache_key = f"schedule:participations:session:{session_id}:gym:{gym_id}:skip:{skip}:limit:{limit}"
        
        # ... (implementar con cache_service.get_or_set, requiere ClassParticipationSchema)
        
        # Por ahora, versi√≥n no cacheada
        return async_class_participation_repository.get_by_session(
            db, session_id=session_id, skip=skip, limit=limit, gym_id=gym_id
        )
    
    async def get_member_participation_status(
        self, db: AsyncSession, member_id: int, start_date: datetime, end_date: datetime,
        gym_id: int, session_ids: Optional[List[int]] = None, redis_client: Optional[Redis] = None
    ) -> List[Dict[str, Any]]:
        """
        Obtener solo los estados de participaci√≥n de un miembro (ultra-optimizado con cach√© agresivo).
        
        Este m√©todo es extremadamente r√°pido porque:
        - Query m√≠nima solo a tabla participation 
        - Cache agresivo con TTL de 5 minutos
        - Sin serializaci√≥n compleja
        - Payload ultra-ligero
        
        Args:
            db: Sesi√≥n de base de datos
            member_id: ID del miembro
            start_date: Fecha inicio (UTC)
            end_date: Fecha fin (UTC)
            gym_id: ID del gimnasio
            session_ids: Lista de session_ids espec√≠ficos (opcional)
            redis_client: Cliente Redis para cache
            
        Returns:
            Lista de diccionarios con estados de participaci√≥n
        """
        # Si no hay Redis, usar versi√≥n sin cach√©
        if not redis_client:
            participations = await async_class_participation_repository.get_member_participation_status(
                db, member_id=member_id, start_date=start_date, end_date=end_date,
                gym_id=gym_id, session_ids=session_ids
            )
            return [self._format_participation_status(p) for p in participations]
        
        # Generar cache key espec√≠fico
        session_ids_str = ",".join(map(str, sorted(session_ids))) if session_ids else "all"
        start_str = start_date.strftime("%Y%m%d")
        end_str = end_date.strftime("%Y%m%d")
        
        cache_key = f"participation_status:{gym_id}:{member_id}:{start_str}:{end_str}:{session_ids_str}"
        tracking_key = f"cache_keys:participation_status:{gym_id}:{member_id}"
        
        # Intentar obtener del cache
        try:
            cached_data = await redis_client.get_async(cache_key)
            if cached_data:
                import json
                return json.loads(cached_data)
        except Exception as e:
            logger.warning(f"Error accessing cache: {e}")
        
        # Si no est√° en cache, consultar BD
        participations = await async_class_participation_repository.get_member_participation_status(
            db, member_id=member_id, start_date=start_date, end_date=end_date,
            gym_id=gym_id, session_ids=session_ids
        )
        
        # Formatear resultados
        formatted_results = [self._format_participation_status(p) for p in participations]
        
        # Guardar en cache con TTL de 5 minutos (datos menos vol√°tiles)
        try:
            import json
            await redis_client.setex(
                cache_key, 
                300,  # 5 minutos 
                json.dumps(formatted_results, default=str)
            )
            # A√±adir a tracking set para invalidaci√≥n
            await redis_client.sadd(tracking_key, cache_key)
            await redis_client.expire(tracking_key, 3600)  # 1 hora de tracking
        except Exception as e:
            logger.warning(f"Error setting cache: {e}")
        
        return formatted_results
    
    def _format_participation_status(self, participation: ClassParticipation) -> Dict[str, Any]:
        """Formatear participaci√≥n a diccionario ultra-ligero"""
        return {
            "session_id": participation.session_id,
            "status": participation.status.value,
            "registration_time": participation.registration_time.isoformat(),
            "attendance_time": participation.attendance_time.isoformat() if participation.attendance_time else None,
            "cancellation_time": participation.cancellation_time.isoformat() if participation.cancellation_time else None
        }
    
    async def invalidate_member_participation_cache(
        self, member_id: int, gym_id: int, redis_client: Optional[Redis] = None
    ):
        """Invalidar cache de participaciones de un miembro espec√≠fico"""
        if not redis_client:
            return
            
        try:
            tracking_key = f"cache_keys:participation_status:{gym_id}:{member_id}"
            cache_keys = await redis_client.smembers(tracking_key)
            
            if cache_keys:
                await redis_client.delete(*cache_keys)
                await redis_client.delete(tracking_key)
                logger.info(f"Invalidated {len(cache_keys)} participation status cache keys for member {member_id}")
        except Exception as e:
            logger.warning(f"Error invalidating participation status cache: {e}")

    async def get_member_participations(
        self, db: AsyncSession, member_id: int, skip: int = 0, limit: int = 100, gym_id: Optional[int] = None, redis_client: Optional[Redis] = None
    ) -> List[Any]:
        """Obtener todas las participaciones de un miembro (con cach√©)"""
        # Nota: A√±adir gym_id y redis_client
        # La clave de cach√© podr√≠a incluir gym_id si es relevante para las participaciones del miembro
        cache_key = f"schedule:participations:member:{member_id}:gym:{gym_id or 'all'}:skip:{skip}:limit:{limit}"
        
        # ... (implementar con cache_service.get_or_set, requiere ClassParticipationSchema)
        
        # Por ahora, versi√≥n no cacheada
        return async_class_participation_repository.get_by_member(
            db, member_id=member_id, skip=skip, limit=limit, gym_id=gym_id
        )
    
    async def get_member_upcoming_classes(
        self, db: AsyncSession, member_id: int, gym_id: int, skip: int = 0, limit: int = 100, 
        redis_client: Optional[Redis] = None
    ) -> List[Dict[str, Any]]:
        """
        Get upcoming classes for a member (with Redis cache).

        Args:
            db (Session): Database session
            member_id (int): ID of the member
            gym_id (int): ID of the gym
            skip (int, optional): Pagination skip. Defaults to 0.
            limit (int, optional): Pagination limit. Defaults to 100.
            redis_client (Optional[Redis], optional): Redis client. Defaults to None.

        Returns:
            List[Dict[str, Any]]: List of dictionaries containing participation and session information
        """
        # Si no hay Redis, usar consulta directa
        if not redis_client:
            return await self._get_member_upcoming_classes_direct(db, member_id, gym_id, skip, limit)
        
        # Crear clave de cach√©
        cache_key = f"schedule:member_upcoming:member:{member_id}:gym:{gym_id}:skip:{skip}:limit:{limit}"
        
        # Funci√≥n para obtener datos de la BD
        async def db_fetch():
            logger.info(f"Cache miss para upcoming classes: member={member_id}, gym={gym_id}")
            return await self._get_member_upcoming_classes_direct(db, member_id, gym_id, skip, limit)
        
        # Intentar obtener de cach√© o generar nuevos datos
        try:
            cached_data = await redis_client.get_async(cache_key)
            
            if cached_data:
                # Cache hit
                logger.debug(f"Cache HIT para upcoming classes: {cache_key}")
                data = json.loads(cached_data)
                
                # Reconstruir objetos desde cache
                result = []
                for item in data:
                    result.append({
                        "participation": ClassParticipationSchema.parse_obj(item["participation"]),
                        "session": ClassSessionSchema.parse_obj(item["session"]),
                        "gym_class": ClassSchema.parse_obj(item["gym_class"])
                    })
                return result
            
            # Cache miss - obtener de BD
            logger.debug(f"Cache MISS para upcoming classes: {cache_key}")
            raw_data = await db_fetch()
            
            # Serializar para cache (convertir objetos Pydantic a dict)
            cache_data = []
            for item in raw_data:
                cache_data.append({
                    "participation": item["participation"].dict(),
                    "session": item["session"].dict(),
                    "gym_class": item["gym_class"].dict()
                })
            
            # Guardar en cach√© (TTL: 5 minutos para datos din√°micos)
            await redis_client.set(
                cache_key,
                json.dumps(cache_data, default=str),  # default=str para datetime
                ex=300  # 5 minutos TTL
            )
            
            logger.debug(f"Datos guardados en cache: {cache_key}")
            return raw_data
            
        except Exception as e:
            logger.error(f"Error en cache para upcoming classes: {e}", exc_info=True)
            # Fallback a consulta directa
            return await self._get_member_upcoming_classes_direct(db, member_id, gym_id, skip, limit)

    async def _get_member_upcoming_classes_direct(
        self, db: AsyncSession, member_id: int, gym_id: int, skip: int = 0, limit: int = 100
    ) -> List[Dict[str, Any]]:
        """
        Consulta directa a BD para obtener clases pr√≥ximas del usuario (m√©todo privado).
        """
        from datetime import timezone
        now = datetime.now(timezone.utc)
        
        # Get the member's upcoming registrations where start_time > now
        upcoming_participations = (
            db.query(ClassParticipation, ClassSession, Class)
            .join(ClassSession, ClassParticipation.session_id == ClassSession.id)
            .join(Class, ClassSession.class_id == Class.id)
            .filter(
                ClassParticipation.member_id == member_id,
                ClassParticipation.gym_id == gym_id,
                ClassSession.start_time > now,
                # Only include registered (not cancelled, attended, or no-show)
                ClassParticipation.status == ClassParticipationStatus.REGISTERED
            )
            .order_by(ClassSession.start_time.asc())
            .offset(skip)
            .limit(limit)
            .all()
        )
        
        # Format the results with proper serialization to avoid PydanticSerializationError
        result = []
        for participation, session, gym_class in upcoming_participations:
            # Convierte los modelos SQLAlchemy a esquemas Pydantic
            result.append({
                "participation": ClassParticipationSchema.parse_obj(participation.__dict__),
                "session": ClassSessionSchema.parse_obj(session.__dict__),
                "gym_class": ClassSchema.parse_obj(gym_class.__dict__)
            })
            
        return result
    
    async def get_member_attendance_history(
        self, db: AsyncSession, member_id: int, gym_id: int, 
        start_date: Optional[datetime] = None, end_date: Optional[datetime] = None,
        skip: int = 0, limit: int = 100, redis_client: Optional[Redis] = None
    ) -> List[Dict[str, Any]]:
        """
        Get attendance history for a member.

        Args:
            db (Session): Database session
            member_id (int): ID of the member
            gym_id (int): ID of the gym
            start_date (Optional[datetime], optional): If provided, only include attendances on or after this date
            end_date (Optional[datetime], optional): If provided, only include attendances on or before this date
            skip (int, optional): Pagination skip. Defaults to 0.
            limit (int, optional): Pagination limit. Defaults to 100.
            redis_client (Optional[Redis], optional): Redis client. Defaults to None.

        Returns:
            List[Dict[str, Any]]: List of dictionaries containing participation and session information
        """
        query = (
            db.query(ClassParticipation, ClassSession, Class)
            .join(ClassSession, ClassParticipation.session_id == ClassSession.id)
            .join(Class, ClassSession.class_id == Class.id)
            .filter(
                ClassParticipation.member_id == member_id,
                ClassParticipation.gym_id == gym_id,
                # Sessions that have already happened
                ClassSession.start_time <= datetime.utcnow()
            )
        )
        
        # Apply date filters if provided
        if start_date:
            query = query.filter(ClassSession.start_time >= start_date)
        if end_date:
            query = query.filter(ClassSession.start_time <= end_date)
        
        # Order by most recent first
        query = query.order_by(ClassSession.start_time.desc())
        
        # Apply pagination
        history = query.offset(skip).limit(limit).all()
        
        # Format the results
        result = []
        for participation, session, gym_class in history:
            result.append({
                "participation": participation,
                "session": session,
                "gym_class": gym_class
            })
            
        return result

    # M√©todo helper para invalidar cach√©s de sesi√≥n cuando cambia una participaci√≥n
    async def _invalidate_session_caches_from_participation(self, session_id: int, gym_id: int, redis_client: Optional[Redis] = None, trainer_id: Optional[int] = None, class_id: Optional[int] = None):
        """
        Invalida las cach√©s relacionadas con una sesi√≥n espec√≠fica cuando cambia una participaci√≥n
        (por ejemplo, un usuario se une o se va).
        
        Esto incluye:
        - Detalles de la sesi√≥n (con y sin disponibilidad).
        - Listas de participantes de esa sesi√≥n.
        - Posiblemente listas generales donde la disponibilidad podr√≠a cambiar (upcoming, range, etc.).
        """
        if not redis_client:
            return
            
        keys_to_delete = []
        patterns_to_delete = []

        # Claves de detalle de la sesi√≥n
        keys_to_delete.append(f"schedule:session:detail:{session_id}")
        keys_to_delete.append(f"schedule:session:detail_with_availability:{session_id}")
        
        # Patr√≥n de participantes de esta sesi√≥n espec√≠fica
        patterns_to_delete.append(f"schedule:participations:session:{session_id}:gym:{gym_id}:*")
        
        # Invalidar listas generales donde la disponibilidad podr√≠a cambiar (m√°s seguro)
        patterns_to_delete.append(f"schedule:sessions:upcoming:gym:{gym_id}:*") 
        patterns_to_delete.append(f"schedule:sessions:range:gym:{gym_id}:*") 
        if trainer_id:
             patterns_to_delete.append(f"schedule:sessions:trainer:{trainer_id}:gym:{gym_id}:*")
        if class_id:
             patterns_to_delete.append(f"schedule:sessions:class:{class_id}:gym:{gym_id}:*")
             
        try:
            if keys_to_delete:
                deleted_keys = await redis_client.delete(*keys_to_delete)
                logger.debug(f"Invalidated {deleted_keys} session detail keys from participation change: {keys_to_delete}")
            
            deleted_pattern_count = 0
            for pattern in patterns_to_delete:
                deleted_count = await cache_service.delete_pattern(redis_client, pattern)
                deleted_pattern_count += deleted_count
                logger.debug(f"Invalidated {deleted_count} keys with pattern from participation change: {pattern}")
            logger.debug(f"Total invalidated keys from patterns due to participation change: {deleted_pattern_count}")
            
        except Exception as e:
             logger.error(f"Error invalidating session cache {session_id} from participation change: {e}", exc_info=True)


# Instantiate services
gym_hours_service = GymHoursService()
gym_special_hours_service = GymSpecialHoursService()
category_service = ClassCategoryService()
class_service = AsyncClassService()
class_session_service = AsyncClassSessionService()
class_participation_service = AsyncClassParticipationService() 